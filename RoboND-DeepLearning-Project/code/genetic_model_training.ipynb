{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-Me Project\n",
    "Congratulations on reaching the final project of the Robotics Nanodegree! \n",
    "\n",
    "Previously, you worked on the Semantic Segmentation lab where you built a deep learning network that locates a particular human target within an image. For this project, you will utilize what you implemented and learned from that lab and extend it to train a deep learning model that will allow a simulated quadcopter to follow around the person that it detects! \n",
    "\n",
    "Most of the code below is similar to the lab with some minor modifications. You can start with your existing solution, and modify and improve upon it to train the best possible model for this task.\n",
    "\n",
    "You can click on any of the following to quickly jump to that part of this notebook:\n",
    "1. [Data Collection](#data)\n",
    "2. [FCN Layers](#fcn)\n",
    "3. [Build the Model](#build)\n",
    "4. [Training](#training)\n",
    "5. [Prediction](#prediction)\n",
    "6. [Evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection<a id='data'></a>\n",
    "We have provided you with a starting dataset for this project. Download instructions can be found in the README for this project's repo.\n",
    "Alternatively, you can collect additional data of your own to improve your model. Check out the \"Collecting Data\" section in the Project Lesson in the Classroom for more details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.keras.python import keras\n",
    "from tensorflow.contrib.keras.python.keras import layers, models\n",
    "\n",
    "from tensorflow import image\n",
    "\n",
    "from utils import scoring_utils\n",
    "from utils.separable_conv2d import SeparableConv2DKeras, BilinearUpSampling2D\n",
    "from utils import data_iterator\n",
    "from utils import plotting_tools \n",
    "from utils import model_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN Layers <a id='fcn'></a>\n",
    "In the Classroom, we discussed the different layers that constitute a fully convolutional network (FCN). The following code will introduce you to the functions that you need to build your semantic segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable Convolutions\n",
    "The Encoder for your FCN will essentially require separable convolution layers, due to their advantages as explained in the classroom. The 1x1 convolution layer in the FCN, however, is a regular convolution. Implementations for both are provided below for your use. Each includes batch normalization with the ReLU activation function applied to the layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separable_conv2d_batchnorm(input_layer, filters, strides=1):\n",
    "    output_layer = SeparableConv2DKeras(filters=filters,kernel_size=3, strides=strides,\n",
    "                             padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    output_layer = layers.BatchNormalization()(output_layer) \n",
    "    return output_layer\n",
    "\n",
    "def conv2d_batchnorm(input_layer, filters, kernel_size=3, strides=1):\n",
    "    output_layer = layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, \n",
    "                      padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    output_layer = layers.BatchNormalization()(output_layer) \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilinear Upsampling\n",
    "The following helper function implements the bilinear upsampling layer. Upsampling by a factor of 2 is generally recommended, but you can try out different factors as well. Upsampling is used in the decoder block of the FCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilinear_upsample(input_layer):\n",
    "    output_layer = BilinearUpSampling2D((2,2))(input_layer)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model <a id='build'></a>\n",
    "In the following cells, you will build an FCN to train a model to detect and locate the hero target within an image. The steps are:\n",
    "- Create an `encoder_block`\n",
    "- Create a `decoder_block`\n",
    "- Build the FCN consisting of encoder block(s), a 1x1 convolution, and decoder block(s).  This step requires experimentation with different numbers of layers and filter sizes to build your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Block\n",
    "Create an encoder block that includes a separable convolution layer using the `separable_conv2d_batchnorm()` function. The `filters` parameter defines the size or depth of the output layer. For example, 32 or 64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_block(input_layer, filters, strides):\n",
    "    \n",
    "    output_layer = separable_conv2d_batchnorm(input_layer, filters, strides)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Block\n",
    "The decoder block is comprised of three parts:\n",
    "- A bilinear upsampling layer using the upsample_bilinear() function. The current recommended factor for upsampling is set to 2.\n",
    "- A layer concatenation step. This step is similar to skip connections. You will concatenate the upsampled small_ip_layer and the large_ip_layer.\n",
    "- Some (one or two) additional separable convolution layers to extract some more spatial information from prior layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoder_block(small_ip_layer, large_ip_layer, filters):\n",
    "    \n",
    "    output_layer = bilinear_upsample(small_ip_layer)\n",
    "    \n",
    "    output_layer = layers.concatenate([output_layer, large_ip_layer])\n",
    "    \n",
    "    output_layer = separable_conv2d_batchnorm(output_layer, filters)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Now that you have the encoder and decoder blocks ready, go ahead and build your FCN architecture! \n",
    "\n",
    "There are three steps:\n",
    "- Add encoder blocks to build the encoder layers. This is similar to how you added regular convolutional layers in your CNN lab.\n",
    "- Add a 1x1 Convolution layer using the conv2d_batchnorm() function. Remember that 1x1 Convolutions require a kernel and stride of 1.\n",
    "- Add decoder blocks for the decoder layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn_model(inputs, num_classes):\n",
    "    \n",
    "    enc_layer1 = encoder_block(inputs, 64, 2)\n",
    "    enc_layer2 = encoder_block(enc_layer1, 128, 2)\n",
    "\n",
    "    # TODO Add 1x1 Convolution layer using conv2d_batchnorm().\n",
    "    one_conv = conv2d_batchnorm(enc_layer2, 256, 1, 1)\n",
    "    \n",
    "    # TODO: Add the same number of Decoder Blocks as the number of Encoder Blocks\n",
    "    dec_layer1 = decoder_block(one_conv, enc_layer1, 128)\n",
    "    x = decoder_block(dec_layer1, inputs, 64)\n",
    "    \n",
    "    # The function returns the output layer of your model. \"x\" is the final layer obtained from the last decoder_block()\n",
    "    return layers.Conv2D(num_classes, 1, activation='softmax', padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training <a id='training'></a>\n",
    "The following cells will use the FCN you created and define an ouput layer based on the size of the processed image and the number of classes recognized. You will define the hyperparameters to compile and train your model.\n",
    "\n",
    "Please Note: For this project, the helper code in `data_iterator.py` will resize the copter images to 160x160x3 to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "image_hw = 160\n",
    "image_shape = (image_hw, image_hw, 3)\n",
    "inputs = layers.Input(image_shape)\n",
    "num_classes = 3\n",
    "\n",
    "# Call fcn_model()\n",
    "output_layer = fcn_model(inputs, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Define and tune your hyperparameters.\n",
    "- **steps_per_epoch**: number of batches of training images that go through the network in 1 epoch. We have provided you with a default value. One recommended value to try would be based on the total number of images in training dataset divided by the batch_size.\n",
    "- **validation_steps**: number of batches of validation images that go through the network in 1 epoch. This is similar to steps_per_epoch, except validation_steps is for the validation dataset. We have provided you with a default value for this as well.\n",
    "- **workers**: maximum number of processes to spin up. This can affect your training speed and is dependent on your hardware. We have provided a recommended value to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = 100\n",
    "validation_steps = 50\n",
    "workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm\n",
    "\n",
    "In this step, I attempt to find optimal hyperparameters by using a genetic algorithm. This is purely for fun and to explore a new concept outside of this course!\n",
    "\n",
    "How does a genetic algorithm work?\n",
    "\n",
    "    1) We create a population of randomly generated members.\n",
    "    2) Next, we score each member of the population based on some goal. This score is called a fitness function.\n",
    "    3) Then, we select and 'breed' the best members of the population to produce more like them.\n",
    "    4) We will then mutate some members randomly to attempt to find even better candidates.\n",
    "    5) Finally, we kill off the rest (survival of the fittest)!\n",
    "\n",
    "After step 5, we have refilled the population to its starting size (via children) and repeat steps 2 - 5. Each cycle through these steps is called a generation. So say we start with a population of 10 members and we want to do 5 generations. After we fit them to a fitness function, we pick the top 3 members of the population and 2 randomly of the 7 worst performing ones (for diversity!). We now have a population of 5 members. At this point, we 'breed' amongst the 5 members (ensuring that the 'mom' and 'dad' are not the same networks) until we regain a population of 10. Then we randomly mutate (by randomly changing the hyperparameters) members of the population. This step would be performed 5 times, to give you 5 generations.\n",
    "\n",
    "#### Why a genetic algorithm\n",
    "\n",
    "Let’s say it takes five minutes to train and evaluate a network on our dataset. And let’s say we have four parameters with five possible settings each. To try them all would take (5**4) * 5 minutes, or 3,125 minutes, or about 52 hours.\n",
    "Now let’s say we use a genetic algorithm to evolve 10 generations with a population of 20, with a plan to keep the top 25% plus a few more, so ~8 per generation. This means that in our first generation we score 20 networks (20 * 5 = 100 minutes). Every generation after that only requires around 12 runs, since we don’t have the score the ones we keep. That’s 100 + (9 generations * 5 minutes * 12 networks) = 640 minutes, or 11 hours. So a genetic algorithm approach to finding optimal hyperparameters is much quicker (in this case, 80%!) than a brute force search approach.\n",
    "\n",
    "I should also note that in addition to keeping a certain percentage of top performers, we will also be keeping a small percentage of hyperparameters that don't perform that well. Why? Well, we want to promote parameter diversity. One of the dangers of optimization algorithms is getting stuck at a local maximum and consequently being unable to find the real maximum. By including some individuals who are not performing as well, we decrease our likelihood of getting stuck. Mutating the childern also help to promote diversity (although the chance of mutation is quite low).\n",
    "\n",
    "\n",
    "#### How this will be implemented for this project\n",
    "\n",
    "Ultimately, this is just an experimentation and a chance for me to look at something new and interesting that can apply to this project and course! Getting the project submitted and accepted is far more important for me to accomplish before running out of AWS credits! However, once accepted, I want to run through a full training session with realistic hyperparameters. Just for the sake of testing and seeing the network run, I have set up two sets of hyperparameters: A test set and a real set. The test set are some simple and quick running hyperparameters solely for the purpose of watching the algorithm work. These will perform terribly, but give quick output of what the network is performing through print statements. If you would like to see the algorithm work, just use the test hyperparameters. Once my project is completed and accepted, I plan on using the rest of my AWS credits to run a full training session using the algorithm and the real hyperparameters. For testing, each generation will consist of 5 individuals, and I run this algorithm for 5 generations. In a real training situation, I would have a population of at least 10 individuals per generations, and run for between 15-20 generations. I tried to comment the code as best as I could to explain the process as I went along.\n",
    "\n",
    "#### Possible improvements\n",
    "\n",
    "This is a rough implementation. I fully conceded that many things could be coded more robustly, but it is good enough to get an idea of how this works! One addition that I am particularly interested in is to include different network architectures as part of the traits. This way I could have multiple different networks, of all different numbers of encoders/decoders/1x1 convolutions, to run and evolve along with the hyperparameters. I would be quite interested in seeing how how the generations evolve and what networks/hyperparameters emerge as the strongest. Hopefully, provided I have enough AWS credits left over, I can find out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, randint\n",
    "\n",
    "# These are being used for test runs, to make sure everything works and to quickly see the genetic algorithm\n",
    "# in action quickly\n",
    "\n",
    "epochs_test = [1, 2, 3]\n",
    "batch_size_test = [6, 12, 24]\n",
    "learning_rate_test = [0.5, 0.1, 0.05]\n",
    "traits_test = [epochs_test, batch_size_test, learning_rate_test]\n",
    "\n",
    "# These are for real runs. This will take a while to go through, so I will test these if I have AWS credits left\n",
    "# over after this project is accepted! In actuality, I would like a few more of each for further testing. I think\n",
    "# it would also be interesting to include different model architectures (more encoding/decoding layers, etc) as part of\n",
    "# the parameters\n",
    "\n",
    "# epochs = [10, 30, 50]\n",
    "# batch_size = [32, 64, 128]\n",
    "# learning_rate = [0.001, 0.005, 0.01]\n",
    "# traits = [epochs, batch_size, learning_rate]\n",
    "\n",
    "def individual():\n",
    "    # The last entry in this list, 0, will later be used to store the fitness of this individual\n",
    "    return [traits[0][randint(0,len(epochs) - 1)], traits[1][randint(0,len(batch_size) - 1)], \n",
    "            traits[2][randint(0, len(learning_rate) - 1)], 0]\n",
    "\n",
    "def population(number):\n",
    "    return [ individual() for x in range(number) ]\n",
    "\n",
    "def breed(father, mother):\n",
    "    # Here, I'm making sure that at least 1 trait comes from both father and mother\n",
    "    # This assumes 3 traits. Could make more robust to allow different number of traits\n",
    "    f_traits = randint(1,2)\n",
    "    \n",
    "    # Build a child using the traits of the parents\n",
    "    # Traits could possibly be randomized a little better\n",
    "    child = father[:f_traits] + mother[f_traits:3] + [0]\n",
    "    return child\n",
    "\n",
    "def mutate(individual):\n",
    "    # This takes a randomly selected trait to swap out in the individual. This incorporates random mutations\n",
    "    # in the population.\n",
    "    trait_to_modify = randint(0, len(traits) - 1)\n",
    "    value_to_modify_with = randint(0, len(traits[trait_to_modify]) - 1)\n",
    "    individual[trait_to_modify] = traits[trait_to_modify][value_to_modify_with]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital generation: [[3, 6, 0.5, 0], [1, 6, 0.1, 0], [3, 6, 0.5, 0], [2, 6, 0.1, 0], [3, 6, 0.5, 0]]\n",
      "Generation: 0, individual: [3, 6, 0.5, 0]\n",
      "Using epochs: 3, batch size: 6, learning rate: 0.5\n",
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2793"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c6f0501d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s - loss: 0.2787 - val_loss: 0.2479\n",
      "Epoch 2/3\n",
      " 43/100 [===========>..................] - ETA: 7s - loss: 0.3706"
     ]
    }
   ],
   "source": [
    "# Generate an initial population of 5 members.\n",
    "generation = population(5)\n",
    "\n",
    "print(\"Inital generation: {}\".format(generation))\n",
    "\n",
    "# In this case, we are doing 5 generations. This can be changed by changing the integer in the below for loop.\n",
    "for i in range(5):\n",
    "    for index, individual in enumerate(generation):\n",
    "        # No need to score top performers networks after first generation.\n",
    "        if i > 0 and index < len(generation) * 0.4:\n",
    "            continue\n",
    "        \n",
    "        print(\"Generation: {}, individual: {}\".format(i, individual))\n",
    "        print(\"Using epochs: {}, batch size: {}, learning rate: {}\".format(individual[0], individual[1], individual[2]))\n",
    "        model = models.Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(individual[2]), loss='categorical_crossentropy')\n",
    "\n",
    "        # Data iterators for loading the training and validation data\n",
    "        train_iter = data_iterator.BatchIteratorSimple(batch_size=individual[1],\n",
    "                                                       data_folder=os.path.join('..', 'data', 'train'),\n",
    "                                                       image_shape=image_shape,\n",
    "                                                       shift_aug=True)\n",
    "\n",
    "        val_iter = data_iterator.BatchIteratorSimple(batch_size=individual[1],\n",
    "                                                     data_folder=os.path.join('..', 'data', 'validation'),\n",
    "                                                     image_shape=image_shape)\n",
    "\n",
    "        logger_cb = plotting_tools.LoggerPlotter()\n",
    "        callbacks = [logger_cb]\n",
    "\n",
    "        model.fit_generator(train_iter,\n",
    "                            steps_per_epoch = steps_per_epoch, # the number of batches per epoch,\n",
    "                            epochs = individual[0], # the number of epochs to train for,\n",
    "                            validation_data = val_iter, # validation iterator\n",
    "                            validation_steps = validation_steps, # the number of batches to validate on\n",
    "                            callbacks=callbacks,\n",
    "                            workers = workers)\n",
    "\n",
    "        run_num = 'run_1'\n",
    "\n",
    "        val_with_targ, pred_with_targ = model_tools.write_predictions_grade_set(model,\n",
    "                                                run_num,'patrol_with_targ', 'sample_evaluation_data') \n",
    "\n",
    "        val_no_targ, pred_no_targ = model_tools.write_predictions_grade_set(model, \n",
    "                                                run_num,'patrol_non_targ', 'sample_evaluation_data') \n",
    "\n",
    "        val_following, pred_following = model_tools.write_predictions_grade_set(model,\n",
    "                                                run_num,'following_images', 'sample_evaluation_data')\n",
    "\n",
    "        true_pos1, false_pos1, false_neg1, iou1 = scoring_utils.score_run_iou(val_following, pred_following)\n",
    "        true_pos2, false_pos2, false_neg2, iou2 = scoring_utils.score_run_iou(val_no_targ, pred_no_targ)\n",
    "        true_pos3, false_pos3, false_neg3, iou3 = scoring_utils.score_run_iou(val_with_targ, pred_with_targ)\n",
    "\n",
    "        true_pos = true_pos1 + true_pos2 + true_pos3\n",
    "        false_pos = false_pos1 + false_pos2 + false_pos3\n",
    "        false_neg = false_neg1 + false_neg2 + false_neg3\n",
    "\n",
    "        weight = true_pos/(true_pos+false_neg+false_pos)\n",
    "\n",
    "        final_IoU = (iou1 + iou3)/2\n",
    "\n",
    "        final_score = final_IoU * weight\n",
    "        print(\"FINAL SCORE: {}\".format(final_score))\n",
    "\n",
    "        # Set score for individual\n",
    "        # For this project, a score of 0.4 was acceptable as passing, but I decided to make the acceptance score a little\n",
    "        # larger.\n",
    "        individual[3] = 0.6 - final_score\n",
    "        print()\n",
    "        print(\"Score for this individual: {0:.10f}\".format(individual[3]))\n",
    "        print()\n",
    "        print()\n",
    "    \n",
    "    print(\"Finishing generation: {}\".format(i))\n",
    "    # If we aren't on the last generation\n",
    "    if i < 5:\n",
    "        # Sort population by fitness, with a lower score meaning a greater fitness\n",
    "        generation = sorted(generation, key=lambda x: x[3])\n",
    "\n",
    "        # Seed the next generation with the top 40% performers, and take 20% of the remaining population as a random\n",
    "        # selected individual.\n",
    "        parents_count = int(len(generation) * 0.4)\n",
    "        random_individual_count = int(len(generation) * 0.2)\n",
    "        survivors_count = (parents_count + random_individual_count) - 1\n",
    "        generation = generation[:parents_count] + [generation[randint(2, 4)] for x in range(random_individual_count)]\n",
    "        \n",
    "        print(\"Top performers and randomly selected individuals: {}\".format(generation))\n",
    "        \n",
    "        # Now we 'breed' the top performers with the randomly selected individuals to replenish the population\n",
    "        while len(generation) < 5:\n",
    "            father = randint(0, survivors_count) \n",
    "            mother = randint(0, survivors_count)\n",
    "\n",
    "            # We don't want the father and mother to be the same individual\n",
    "            if father == mother:\n",
    "                continue\n",
    "            else:\n",
    "                child = breed(generation[father], generation[mother])\n",
    "                print(\"Child: {}\".format(child))\n",
    "                generation.append(child)\n",
    "                \n",
    "        print(\"Repopulated: {}\".format(generation))\n",
    "        \n",
    "        # Next we introduce random mutation (2% chance) to the children and least performing network\n",
    "        chance_to_mutate = 0.02\n",
    "        for entity in generation[survivors_count:]:\n",
    "            if chance_to_mutate > random():\n",
    "                print(\"Mutating child\")\n",
    "                mutate(entity)\n",
    "\n",
    "\n",
    "                \n",
    "    print(\"New generation: {}\".format(generation))\n",
    "    print()\n",
    "            \n",
    "    \n",
    "for i in generation:\n",
    "    print(\"Epochs: {}\", i[0])\n",
    "    print(\"Batch size: {}\", i[1])\n",
    "    print(\"Learning rate: {}\", i[2])\n",
    "    print(\"Final score: {}\", i[3])\n",
    "    \n",
    "print(\"Top performing hyperparameters: {}\".format(generation[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
